"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π LLM
"""
import requests
import json
from typing import List, Dict, Any
from config import ARTIFACTS_STRUCTURE

class LLMAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π LLM"""
    
    def __init__(self, llm_config):
        self.config = llm_config
        self.base_url = llm_config.base_url.rstrip('/')
        self.headers = {
            'X-PROXY-AUTH': llm_config.proxy_token,
            'Content-Type': 'application/json'
        }
    
    def analyze_documents(self, documents: List[Dict[str, Any]], project_types: List[str]) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –Ω–∞—Ö–æ–¥–∏—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
        
        Args:
            documents: –°–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            project_types: –í—ã–±—Ä–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã –ø—Ä–æ–µ–∫—Ç–æ–≤
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏
        """
        print("ü§ñ –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π LLM...")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        context = self._build_analysis_context(documents, project_types)
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
        prompt = self._create_analysis_prompt(context, project_types)
        
        try:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π LLM
            response = self._send_llm_request(prompt)
            
            if response:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
                analysis_result = self._parse_llm_response(response)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
                analysis_result['analyzed_documents'] = self._prepare_documents_info(documents)
                
                print("‚úÖ –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                return analysis_result
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç LLM")
                return self._create_empty_result(project_types, documents)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ LLM: {str(e)}")
            return self._create_empty_result(project_types, documents)
    
    def _send_llm_request(self, prompt: str) -> str:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π LLM"""
        try:
            url = f"{self.base_url}/api/chat"
            
            payload = {
                "model": self.config.model,
                "stream": self.config.stream,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            }
            
            print(f"üì° –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –∫ LLM: {url}")
            print(f"ü§ñ –ú–æ–¥–µ–ª—å: {self.config.model}")
            
            response = requests.post(
                url,
                headers=self.headers,
                json=payload,
                timeout=120  # 2 –º–∏–Ω—É—Ç—ã timeout –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            )
            
            if response.status_code == 200:
                response_data = response.json()
                content = response_data.get('message', {}).get('content', '')
                
                if content:
                    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç LLM ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
                    return content
                else:
                    print("‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LLM")
                    return ""
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ HTTP {response.status_code}: {response.text}")
                return ""
                
        except requests.exceptions.Timeout:
            print("‚è±Ô∏è –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ LLM")
            return ""
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ LLM: {str(e)}")
            return ""
    
    def get_available_models(self) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            url = f"{self.base_url}/v1/models"
            
            response = requests.get(url, headers=self.headers, timeout=30)
            
            if response.status_code == 200:
                models_data = response.json()
                models = [model.get('id', '') for model in models_data.get('data', [])]
                print(f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {', '.join(models)}")
                return models
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π HTTP {response.status_code}")
                return []
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {str(e)}")
            return []
    
    def _build_analysis_context(self, documents: List[Dict[str, Any]], project_types: List[str]) -> str:
        """–°—Ç—Ä–æ–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        context = "–î–û–ö–£–ú–ï–ù–¢–´ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:\n\n"
        
        for i, doc in enumerate(documents, 1):
            context += f"–î–û–ö–£–ú–ï–ù–¢ {i}: {doc['name']}\n"
            context += f"–¢–∏–ø: {doc['type']}\n"
            
            if doc['type'] == 'file':
                context += f"–§–æ—Ä–º–∞—Ç: {doc['format']}\n"
            elif doc['type'] == 'confluence':
                context += f"URL: {doc['url']}\n"
                
            context += f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {doc['pages']}\n"
            context += "–°–û–î–ï–†–ñ–ò–ú–û–ï:\n"
            context += doc['text'][:8000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
            
            if len(doc['text']) > 8000:
                context += "\n... (—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ–±—Ä–µ–∑–∞–Ω–æ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤) ...\n"
                
            context += "\n" + "="*80 + "\n\n"
        
        return context
    
    def _create_analysis_prompt(self, context: str, project_types: List[str]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ LLM"""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –Ω—É–∂–Ω–æ –∏—Å–∫–∞—Ç—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–æ–≤ –ø—Ä–æ–µ–∫—Ç–æ–≤
        artifacts_to_find = []
        
        # –û–±—â–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–∞–µ–º
        artifacts_to_find.extend(ARTIFACTS_STRUCTURE['general']['items'])
        artifacts_to_find.extend(ARTIFACTS_STRUCTURE['technical']['items'])
        artifacts_to_find.extend(ARTIFACTS_STRUCTURE['operations']['items'])
        artifacts_to_find.extend(ARTIFACTS_STRUCTURE['testing']['items'])
        artifacts_to_find.extend(ARTIFACTS_STRUCTURE['changes']['items'])
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è —Ç–∏–ø–æ–≤ –ø—Ä–æ–µ–∫—Ç–æ–≤
        for project_type in project_types:
            if project_type.lower() == 'bi':
                artifacts_to_find.extend(ARTIFACTS_STRUCTURE['bi']['items'])
            elif project_type.lower() == 'dwh':
                artifacts_to_find.extend(ARTIFACTS_STRUCTURE['dwh']['items'])
            elif project_type.lower() == 'rpa':
                artifacts_to_find.extend(ARTIFACTS_STRUCTURE['rpa']['items'])
        
        prompt = f"""
–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –ò–¢ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –Ω–∞–π—Ç–∏ —Å–ª–µ–¥—É—é—â–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞.

–¢–ò–ü–´ –ü–†–û–ï–ö–¢–û–í: {', '.join(project_types)}

–ê–†–¢–ï–§–ê–ö–¢–´ –î–õ–Ø –ü–û–ò–°–ö–ê:
"""
        
        for i, artifact in enumerate(artifacts_to_find, 1):
            prompt += f"{i}. {artifact}\n"
        
        prompt += f"""

{context}

–ò–ù–°–¢–†–£–ö–¶–ò–ò –ü–û –ê–ù–ê–õ–ò–ó–£:
1. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ —É–∫–∞–∂–∏:
   - –ù–ê–ô–î–ï–ù –∏–ª–∏ –ù–ï –ù–ê–ô–î–ï–ù
   - –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω: –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–∏–ª–∏ —Ä–∞–∑–¥–µ–ª)
   - –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)

2. –ë—É–¥—å —Ç–æ—á–Ω—ã–º –≤ —É–∫–∞–∑–∞–Ω–∏–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ - –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –∏ —Å—Ç—Ä–∞–Ω–∏—Ü—É

3. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —á–∞—Å—Ç–∏—á–Ω–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –Ω–æ –Ω–µ–ø–æ–ª–Ω–∞—è, –æ—Ç–º–µ—Ç—å —ç—Ç–æ –∫–∞–∫ "–ß–ê–°–¢–ò–ß–ù–û –ù–ê–ô–î–ï–ù"

4. –ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:

–†–ï–ó–£–õ–¨–¢–ê–¢ –ê–ù–ê–õ–ò–ó–ê:

–ê–†–¢–ï–§–ê–ö–¢: [–ù–∞–∑–≤–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞]
–°–¢–ê–¢–£–°: [–ù–ê–ô–î–ï–ù/–ù–ï –ù–ê–ô–î–ï–ù/–ß–ê–°–¢–ò–ß–ù–û –ù–ê–ô–î–ï–ù]
–ò–°–¢–û–ß–ù–ò–ö: [–ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞, —Å—Ç—Ä–∞–Ω–∏—Ü–∞/—Ä–∞–∑–¥–µ–ª]
–û–ü–ò–°–ê–ù–ò–ï: [–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏]
---

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤—Å–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏ –¥–∞–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
"""
        
        return prompt
    
    def _parse_llm_response(self, response_text: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç LLM –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
        result = {
            'found_artifacts': [],
            'not_found_artifacts': [],
            'partially_found_artifacts': [],
            'analyzed_documents': [],  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø–æ–∑–∂–µ
            'summary': {
                'total_artifacts': 0,
                'found_count': 0,
                'not_found_count': 0,
                'partially_found_count': 0
            }
        }
        
        # –†–∞–∑–±–∏—Ä–∞–µ–º –æ—Ç–≤–µ—Ç LLM
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            print(f"üîç –û—Ç–ª–∞–¥–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ LLM:")
            print(f"   –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(response_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"   –ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤: {response_text[:500]}")
            
            # –ò—â–µ–º –±–ª–æ–∫–∏ —Å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏ - –ø—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
            blocks = response_text.split('–ê–†–¢–ï–§–ê–ö–¢:')
            if len(blocks) <= 1:  # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç
                blocks = [block for block in response_text.split('–ê–†–¢–ï–§–ê–ö–¢') if block.strip()]
            print(f"   –ù–∞–π–¥–µ–Ω–æ –±–ª–æ–∫–æ–≤ –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è: {len(blocks)}")
            
            # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ split('–ê–†–¢–ï–§–ê–ö–¢:'), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—ã–π –±–ª–æ–∫
            # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ split('–ê–†–¢–ï–§–ê–ö–¢'), –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –±–ª–æ–∫–∏
            start_index = 1 if '–ê–†–¢–ï–§–ê–ö–¢:' in response_text else 0
            
            for i, block in enumerate(blocks[start_index:], 1):
                print(f"   –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –±–ª–æ–∫ {i}: {block[:100]}...")
                artifact_info = self._parse_artifact_block(block)
                if artifact_info:
                    print(f"   ‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω –∞—Ä—Ç–µ—Ñ–∞–∫—Ç: {artifact_info['name']} - {artifact_info['status']}")
                    status = artifact_info['status'].upper()
                    
                    if '–ù–ê–ô–î–ï–ù' in status and '–ù–ï –ù–ê–ô–î–ï–ù' not in status:
                        if '–ß–ê–°–¢–ò–ß–ù–û' in status:
                            result['partially_found_artifacts'].append(artifact_info)
                            result['summary']['partially_found_count'] += 1
                        else:
                            result['found_artifacts'].append(artifact_info)
                            result['summary']['found_count'] += 1
                    else:
                        result['not_found_artifacts'].append(artifact_info)
                        result['summary']['not_found_count'] += 1
                    
                    result['summary']['total_artifacts'] += 1
                else:
                    print(f"   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç –≤ –±–ª–æ–∫–µ {i}")
            
            print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞: {result['summary']['total_artifacts']} –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –æ—Ç–≤–µ—Ç–∞ LLM: {str(e)}")
            
        return result
    
    def _parse_artifact_block(self, block: str) -> Dict[str, str]:
        """–ü–∞—Ä—Å–∏—Ç –±–ª–æ–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–µ"""
        try:
            lines = [line.strip() for line in block.split('\n') if line.strip()]
            
            artifact_info = {
                'name': '',
                'status': '',
                'source': '',
                'description': ''
            }
            
            for line in lines:
                if line.startswith('–°–¢–ê–¢–£–°:'):
                    artifact_info['status'] = line.replace('–°–¢–ê–¢–£–°:', '').strip()
                elif line.startswith('–ò–°–¢–û–ß–ù–ò–ö:'):
                    artifact_info['source'] = line.replace('–ò–°–¢–û–ß–ù–ò–ö:', '').strip()
                elif line.startswith('–û–ü–ò–°–ê–ù–ò–ï:'):
                    artifact_info['description'] = line.replace('–û–ü–ò–°–ê–ù–ò–ï:', '').strip()
                elif line.startswith('---'):
                    break
                elif not artifact_info['name'] and not any(line.startswith(prefix) for prefix in ['–°–¢–ê–¢–£–°:', '–ò–°–¢–û–ß–ù–ò–ö:', '–û–ü–ò–°–ê–ù–ò–ï:']):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –∏–∑ —Å—Ç—Ä–æ–∫ –≤–∏–¥–∞ "1: –ù–∞–∑–≤–∞–Ω–∏–µ" –∏–ª–∏ "–ù–∞–∑–≤–∞–Ω–∏–µ"
                    name_line = line.strip()
                    if ':' in name_line and name_line.split(':')[0].strip().isdigit():
                        # –§–æ—Ä–º–∞—Ç "1: –ù–∞–∑–≤–∞–Ω–∏–µ"
                        artifact_info['name'] = ':'.join(name_line.split(':')[1:]).strip()
                    else:
                        # –û–±—ã—á–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
                        artifact_info['name'] = name_line
            
            return artifact_info if artifact_info['name'] else None
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –±–ª–æ–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞: {str(e)}")
            return None
    
    def _prepare_documents_info(self, documents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö"""
        documents_info = []
        
        for doc in documents:
            doc_info = {
                'name': doc.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç'),
                'type': doc.get('type', 'unknown'),
                'pages': doc.get('pages', 0),
                'text_length': len(doc.get('text', ''))
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–æ–ª—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            if doc['type'] == 'file':
                doc_info['format'] = doc.get('format', '')
                doc_info['size_bytes'] = doc.get('size', 0)
            elif doc['type'] == 'confluence':
                doc_info['url'] = doc.get('url', '')
                doc_info['last_modified'] = doc.get('last_modified', '')
            
            documents_info.append(doc_info)
        
        return documents_info
    
    def _create_empty_result(self, project_types: List[str], documents: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏"""
        result = {
            'found_artifacts': [],
            'not_found_artifacts': [],
            'partially_found_artifacts': [],
            'summary': {
                'total_artifacts': 0,
                'found_count': 0,
                'not_found_count': 0,
                'partially_found_count': 0
            },
            'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã'
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö, –¥–∞–∂–µ –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è
        if documents:
            result['analyzed_documents'] = self._prepare_documents_info(documents)
        else:
            result['analyzed_documents'] = []
        
        return result 
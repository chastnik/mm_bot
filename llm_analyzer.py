"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π LLM
"""
import requests
import json
from typing import List, Dict, Any
from config import ARTIFACTS_STRUCTURE

class LLMAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π LLM"""
    
    def __init__(self, llm_config):
        self.config = llm_config
        self.base_url = llm_config.base_url.rstrip('/')
        self.headers = {
            'X-PROXY-AUTH': llm_config.proxy_token,
            'Content-Type': 'application/json'
        }
    
    def analyze_documents(self, documents: List[Dict[str, Any]], project_types: List[str]) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –Ω–∞—Ö–æ–¥–∏—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –ø–æ—ç—Ç–∞–ø–Ω–æ
        
        Args:
            documents: –°–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            project_types: –í—ã–±—Ä–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã –ø—Ä–æ–µ–∫—Ç–æ–≤
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞–º–∏
        """
        print("ü§ñ –ù–∞—á–∏–Ω–∞—é –ø–æ—ç—Ç–∞–ø–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π LLM...")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        all_artifacts = self._get_all_required_artifacts(project_types)
        print(f"üìã –í—Å–µ–≥–æ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(all_artifacts)}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–æ–¥–∏–Ω —Ä–∞–∑ –¥–ª—è –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤)
        context = self._build_analysis_context(documents, project_types)
        
        # –° 64K –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –º–æ–∂–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –±–æ–ª—å—à–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –∑–∞ —Ä–∞–∑
        batch_size = 15  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        artifact_batches = []
        for i in range(0, len(all_artifacts), batch_size):
            artifact_batches.append(all_artifacts[i:i + batch_size])
        
        print(f"üîÑ –ê–Ω–∞–ª–∏–∑ –±—É–¥–µ—Ç –ø—Ä–æ–≤–µ–¥–µ–Ω –≤ {len(artifact_batches)} —ç—Ç–∞–ø–æ–≤")
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        combined_result = {
            'found_artifacts': [],
            'not_found_artifacts': [],
            'partially_found_artifacts': [],
            'analyzed_documents': [],
            'summary': {
                'total_artifacts': 0,
                'found_count': 0,
                'not_found_count': 0,
                'partially_found_count': 0
            }
        }
        
        try:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –±–∞—Ç—á
            for batch_num, artifacts_batch in enumerate(artifact_batches, 1):
                print(f"üîç –≠—Ç–∞–ø {batch_num}/{len(artifact_batches)}: –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é {len(artifacts_batch)} –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤...")
                
                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –±–∞—Ç—á–∞
                prompt = self._create_analysis_prompt(context, artifacts_batch, batch_num, len(artifact_batches))
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
                response = self._send_llm_request(prompt)
                
                if response:
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –±–∞—Ç—á–∞
                    batch_result = self._parse_llm_response(response, artifacts_batch)
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    combined_result['found_artifacts'].extend(batch_result['found_artifacts'])
                    combined_result['not_found_artifacts'].extend(batch_result['not_found_artifacts'])
                    combined_result['partially_found_artifacts'].extend(batch_result['partially_found_artifacts'])
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏
                    combined_result['summary']['found_count'] += batch_result['summary']['found_count']
                    combined_result['summary']['not_found_count'] += batch_result['summary']['not_found_count']
                    combined_result['summary']['partially_found_count'] += batch_result['summary']['partially_found_count']
                    combined_result['summary']['total_artifacts'] += batch_result['summary']['total_artifacts']
                    
                    print(f"‚úÖ –≠—Ç–∞–ø {batch_num} –∑–∞–≤–µ—Ä—à–µ–Ω: –Ω–∞–π–¥–µ–Ω–æ {batch_result['summary']['found_count']} –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤")
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ {batch_num}")
                    # –î–æ–±–∞–≤–ª—è–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —Ç–µ–∫—É—â–µ–≥–æ –±–∞—Ç—á–∞ –∫–∞–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ
                    for artifact in artifacts_batch:
                        combined_result['not_found_artifacts'].append({
                            'name': artifact,
                            'status': '–ù–ï –ù–ê–ô–î–ï–ù',
                            'source': '–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞',
                            'description': '–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ LLM'
                        })
                        combined_result['summary']['not_found_count'] += 1
                        combined_result['summary']['total_artifacts'] += 1
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
            combined_result['analyzed_documents'] = self._prepare_documents_info(documents)
            
            print(f"üéâ –ü–æ—ç—Ç–∞–ø–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {combined_result['summary']['found_count']}/{combined_result['summary']['total_artifacts']} –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –Ω–∞–π–¥–µ–Ω–æ")
            return combined_result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—ç—Ç–∞–ø–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {str(e)}")
            return self._create_empty_result(project_types, documents)
    
    def _send_llm_request(self, prompt: str) -> str:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–π LLM"""
        try:
            url = f"{self.base_url}/api/chat"
            
            payload = {
                "model": self.config.model,
                "stream": self.config.stream,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "options": {
                    "num_ctx": self.config.num_ctx  # 64K —Ç–æ–∫–µ–Ω–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                }
            }
            
            print(f"üì° –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –∫ LLM: {url}")
            print(f"ü§ñ –ú–æ–¥–µ–ª—å: {self.config.model}")
            
            response = requests.post(
                url,
                headers=self.headers,
                json=payload,
                timeout=300  # 5 –º–∏–Ω—É—Ç timeout –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
            )
            
            if response.status_code == 200:
                response_data = response.json()
                content = response_data.get('message', {}).get('content', '')
                
                if content:
                    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç LLM ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
                    return content
                else:
                    print("‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LLM")
                    return ""
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ HTTP {response.status_code}: {response.text}")
                return ""
                
        except requests.exceptions.Timeout:
            print("‚è±Ô∏è –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ LLM")
            return ""
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ LLM: {str(e)}")
            return ""
    
    def get_available_models(self) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            url = f"{self.base_url}/v1/models"
            
            response = requests.get(url, headers=self.headers, timeout=30)
            
            if response.status_code == 200:
                models_data = response.json()
                models = [model.get('id', '') for model in models_data.get('data', [])]
                print(f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {', '.join(models)}")
                return models
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π HTTP {response.status_code}")
                return []
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {str(e)}")
            return []
    
    def _build_analysis_context(self, documents: List[Dict[str, Any]], project_types: List[str]) -> str:
        """–°—Ç—Ä–æ–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        context = "–î–û–ö–£–ú–ï–ù–¢–´ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:\n\n"
        
        for i, doc in enumerate(documents, 1):
            context += f"–î–û–ö–£–ú–ï–ù–¢ {i}: {doc['name']}\n"
            context += f"–¢–∏–ø: {doc['type']}\n"
            
            if doc['type'] == 'file':
                context += f"–§–æ—Ä–º–∞—Ç: {doc['format']}\n"
                context += f"–ò–°–¢–û–ß–ù–ò–ö: –§–∞–π–ª '{doc['name']}'\n"
            elif doc['type'] == 'confluence':
                context += f"URL: {doc['url']}\n"
                # –î–ª—è Confluence –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
                if 'child_pages_count' in doc and doc['child_pages_count'] > 0:
                    context += f"–°–¢–†–£–ö–¢–£–†–ê: –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ + {doc['child_pages_count']} –¥–æ—á–µ—Ä–Ω–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü\n"
                    if 'main_attachments_count' in doc:
                        context += f"–§–ê–ô–õ–´: {doc['main_attachments_count']} –Ω–∞ –≥–ª–∞–≤–Ω–æ–π, {doc.get('child_attachments_count', 0)} –Ω–∞ –¥–æ—á–µ—Ä–Ω–∏—Ö\n"
                context += f"–ò–°–¢–û–ß–ù–ò–ö: Confluence —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∏ –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã\n"
                
            context += f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {doc['pages']}\n"
            context += "\n–°–û–î–ï–†–ñ–ò–ú–û–ï (—Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤):\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ç–∫—É –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            content = doc['text']
            
            # –ò—â–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ —Ñ–∞–π–ª–æ–≤ –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ç–∫—É –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            lines = content.split('\n')
            enhanced_content = []
            current_source = ""
            
            for line in lines:
                if line.startswith('--- –í–õ–û–ñ–ï–ù–ù–´–ô –§–ê–ô–õ'):
                    if '–≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞' in line:
                        file_name = line.split(':')[1].split('---')[0].strip()
                        current_source = f"[–§–ê–ô–õ: {file_name}, CONFLUENCE: –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞]"
                    elif '—Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã' in line:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                        parts = line.split("'")
                        if len(parts) >= 4:
                            confluence_page = parts[1]
                            file_name = parts[3].replace('):', '').strip()
                            current_source = f"[–§–ê–ô–õ: {file_name}, CONFLUENCE: {confluence_page}]"
                    enhanced_content.append(f"\n{current_source}")
                    enhanced_content.append(line)
                elif line.startswith('--- –î–û–ß–ï–†–ù–Ø–Ø –°–¢–†–ê–ù–ò–¶–ê'):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã Confluence
                    page_title = line.split(':')[1].split('---')[0].strip()
                    current_source = f"[CONFLUENCE: {page_title}]"
                    enhanced_content.append(f"\n{current_source}")
                    enhanced_content.append(line)
                elif line.startswith('--- –ì–õ–ê–í–ù–ê–Ø –°–¢–†–ê–ù–ò–¶–ê'):
                    page_title = line.split(':')[1].split('---')[0].strip()
                    current_source = f"[CONFLUENCE: {page_title} (–≥–ª–∞–≤–Ω–∞—è)]"
                    enhanced_content.append(f"\n{current_source}")
                    enhanced_content.append(line)
                else:
                    enhanced_content.append(line)
            
            enhanced_text = '\n'.join(enhanced_content)
            
            # –° —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º LLM –º–æ–∂–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª—å—à–µ
            max_doc_length = 100000  # 100K —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç —Å 64K –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            if len(enhanced_text) > max_doc_length:
                # –î–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –±–µ—Ä–µ–º –±–æ–ª—å—à–µ –Ω–∞—á–∞–ª–∞ (—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ, –≤–≤–µ–¥–µ–Ω–∏–µ) 
                # –∏ –º–µ–Ω—å—à–µ –∫–æ–Ω—Ü–∞ (–æ–±—ã—á–Ω–æ –º–µ–Ω–µ–µ –≤–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏)
                start_part = enhanced_text[:int(max_doc_length * 0.7)]  # 70% –≤ –Ω–∞—á–∞–ª–µ
                end_part = enhanced_text[-int(max_doc_length * 0.3):]    # 30% –≤ –∫–æ–Ω—Ü–µ
                context += start_part
                context += f"\n... (—Å—Ä–µ–¥–Ω—è—è —á–∞—Å—Ç—å –æ–±—Ä–µ–∑–∞–Ω–∞, –ø–æ–∫–∞–∑–∞–Ω–æ {int(max_doc_length * 0.7)} —Å–∏–º–≤. –Ω–∞—á–∞–ª–∞ –∏ {int(max_doc_length * 0.3)} —Å–∏–º–≤. –∫–æ–Ω—Ü–∞) ...\n"
                context += end_part
                print(f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç '{doc['name']}' –æ–±—Ä–µ–∑–∞–Ω: {len(enhanced_text)} ‚Üí {max_doc_length} —Å–∏–º–≤–æ–ª–æ–≤")
            else:
                context += enhanced_text
                print(f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç '{doc['name']}': {len(enhanced_text)} —Å–∏–º–≤–æ–ª–æ–≤ (–±–µ–∑ –æ–±—Ä–µ–∑–∫–∏)")
                
            context += "\n" + "="*80 + "\n\n"
        
        # –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        print(f"üìä –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {len(context)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–∞–∂–µ –ø–æ—Å–ª–µ –æ–±—Ä–µ–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ - –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è  
        max_total_context = 300000  # 300–ö —Å–∏–º–≤–æ–ª–æ–≤ —Å 64K –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º LLM
        if len(context) > max_total_context:
            print(f"‚ö†Ô∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç ({len(context)} > {max_total_context}), –ø—Ä–∏–º–µ–Ω—è—é –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é...")
            
            # –û–±—Ä–µ–∑–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∫—Ä–∏—Ç–∏—á–Ω–æ
            context = context[:max_total_context]
            context += "\n\n... (–∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω –∏–∑-–∑–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π —Ä–∞–∑–º–µ—Ä–∞) ..."
            print(f"‚úÇÔ∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–æ {len(context)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return context
    
    def _get_all_required_artifacts(self, project_types: List[str]) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤"""
        artifacts_to_find = []
        
        # –í—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –±–∞–∑–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        artifacts_to_find.extend(ARTIFACTS_STRUCTURE['general']['items'])
        artifacts_to_find.extend(ARTIFACTS_STRUCTURE['technical']['items'])
        artifacts_to_find.extend(ARTIFACTS_STRUCTURE['operations']['items'])
        artifacts_to_find.extend(ARTIFACTS_STRUCTURE['testing']['items'])
        artifacts_to_find.extend(ARTIFACTS_STRUCTURE['changes']['items'])
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è —Ç–∏–ø–æ–≤ –ø—Ä–æ–µ–∫—Ç–æ–≤
        for project_type in project_types:
            if project_type.lower() == 'bi':
                artifacts_to_find.extend(ARTIFACTS_STRUCTURE['bi']['items'])
            elif project_type.lower() == 'dwh':
                artifacts_to_find.extend(ARTIFACTS_STRUCTURE['dwh']['items'])
            elif project_type.lower() == 'rpa':
                artifacts_to_find.extend(ARTIFACTS_STRUCTURE['rpa']['items'])
        
        return artifacts_to_find

    def _create_analysis_prompt(self, context: str, artifacts_batch: List[str], batch_number: int, total_batches: int) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ LLM –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –±–∞—Ç—á–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤"""
        
        print(f"üìù –°–æ–∑–¥–∞—é –ø—Ä–æ–º–ø—Ç –¥–ª—è –±–∞—Ç—á–∞ {batch_number}:")
        print(f"   –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤ –±–∞—Ç—á–µ: {artifacts_batch}")
        
        prompt = f"""
–ê–ù–ê–õ–ò–ó –î–û–ö–£–ú–ï–ù–¢–û–í - –≠–¢–ê–ü {batch_number} –∏–∑ {total_batches}

–í–ê–ñ–ù–û: 
- –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –¢–û–õ–¨–ö–û –∑–∞–¥–∞–Ω–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –∏–∑ —Å–ø–∏—Å–∫–∞ –Ω–∏–∂–µ
- –ù–ï –¥–æ–±–∞–≤–ª—è–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
- –ù–ï –∏–∑–º–µ–Ω—è–π –Ω–∞–∑–≤–∞–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
- –û—Ç–≤–µ—á–∞–π –°–¢–†–û–ì–û –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É

–î–û–ö–£–ú–ï–ù–¢–´ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
{context}

–ù–ê–ô–î–ò –í –î–û–ö–£–ú–ï–ù–¢–ê–• –°–õ–ï–î–£–Æ–©–ò–ï {len(artifacts_batch)} –ê–†–¢–ï–§–ê–ö–¢–û–í:

"""
        
        # –î–∞–µ–º –≥–æ—Ç–æ–≤—ã–π —à–∞–±–ª–æ–Ω –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –≤ –±–∞—Ç—á–µ
        for i, artifact in enumerate(artifacts_batch, 1):
            prompt += f"""**–ê–†–¢–ï–§–ê–ö–¢: {artifact}**
* –°–¢–ê–¢–£–°: [–ù–ê–ô–î–ï–ù / –ù–ï –ù–ê–ô–î–ï–ù / –ß–ê–°–¢–ò–ß–ù–û –ù–ê–ô–î–ï–ù]
* –ò–°–¢–û–ß–ù–ò–ö: [–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∞–π–ª –∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞, –≥–¥–µ –Ω–∞–π–¥–µ–Ω]
* –û–ü–ò–°–ê–ù–ò–ï: [–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏]

"""
        
        prompt += f"""
–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –û–¢–í–ï–¢–£:
1. –û—Ç–≤–µ—Ç—å –¥–ª—è –ö–ê–ñ–î–û–ì–û –∏–∑ {len(artifacts_batch)} –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤—ã—à–µ
2. –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–ß–ù–û —Ç–æ—Ç –∂–µ —Ñ–æ—Ä–º–∞—Ç —Å **–ê–†–¢–ï–§–ê–ö–¢:** –∏ –∑–≤–µ–∑–¥–æ—á–∫–∞–º–∏ *
3. –ù–ï –º–µ–Ω—è–π –Ω–∞–∑–≤–∞–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ - –∫–æ–ø–∏—Ä—É–π –∏—Ö —Ç–æ—á–Ω–æ
4. –ó–∞–ø–æ–ª–Ω–∏ —Ç–æ–ª—å–∫–æ –°–¢–ê–¢–£–°, –ò–°–¢–û–ß–ù–ò–ö –∏ –û–ü–ò–°–ê–ù–ò–ï
5. –ï—Å–ª–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–∞–ø–∏—à–∏ –°–¢–ê–¢–£–°: –ù–ï –ù–ê–ô–î–ï–ù

–ù–ê–ß–ò–ù–ê–ô –ê–ù–ê–õ–ò–ó:
"""
        
        return prompt
    
    def _parse_llm_response(self, response_text: str, expected_artifacts: List[str] = None) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç LLM –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
        result = {
            'found_artifacts': [],
            'not_found_artifacts': [],
            'partially_found_artifacts': [],
            'analyzed_documents': [],  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø–æ–∑–∂–µ
            'summary': {
                'total_artifacts': 0,
                'found_count': 0,
                'not_found_count': 0,
                'partially_found_count': 0
            }
        }
        
        # –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –ü–ê–†–°–ò–ù–ì - –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–∂–∏–¥–∞–µ–º—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
        print(f"üîç –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ LLM:")
        print(f"   –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(response_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –û–∂–∏–¥–∞–µ–º—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã: {expected_artifacts}")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–∂–∏–¥–∞–µ–º—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤: {len(expected_artifacts) if expected_artifacts else 0}")
        print(f"   –ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤: {response_text[:500]}")
        
        try:
            # –í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É, –µ—Å–ª–∏ –µ—Å—Ç—å –æ–∂–∏–¥–∞–µ–º—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
            if expected_artifacts:
                print(f"üîß –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Ä–µ–∂–∏–º: —Å–æ–∑–¥–∞—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è {len(expected_artifacts)} –æ–∂–∏–¥–∞–µ–º—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤")
                
                # –°–Ω–∞—á–∞–ª–∞ —Ä–∞–∑–±–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ –±–ª–æ–∫–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                import re
                blocks = []
                if '**–ê–†–¢–ï–§–ê–ö–¢:' in response_text:
                    blocks = response_text.split('**–ê–†–¢–ï–§–ê–ö–¢:')[1:]
                elif '**' in response_text:
                    # –ò—â–µ–º –ª—é–±—ã–µ –±–ª–æ–∫–∏ —Å –∑–≤–µ–∑–¥–æ—á–∫–∞–º–∏
                    artifact_pattern = r'\*\*\s*([^*\n]+?)\s*\*\*'
                    matches = re.finditer(artifact_pattern, response_text, re.MULTILINE | re.IGNORECASE)
                    for match in matches:
                        start_pos = match.start()
                        # –ù–∞–π–¥–µ–º —Å–ª–µ–¥—É—é—â–∏–π –±–ª–æ–∫ –∏–ª–∏ –∫–æ–Ω–µ—Ü —Ç–µ–∫—Å—Ç–∞
                        remaining_text = response_text[match.end():]
                        next_match = re.search(artifact_pattern, remaining_text)
                        if next_match:
                            end_pos = match.end() + next_match.start()
                        else:
                            end_pos = len(response_text)
                        blocks.append(response_text[start_pos:end_pos])
                
                print(f"   –ù–∞–π–¥–µ–Ω–æ {len(blocks)} –±–ª–æ–∫–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ")
                
                for i, artifact_name in enumerate(expected_artifacts):
                    print(f"   üìã –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∞—Ä—Ç–µ—Ñ–∞–∫—Ç {i+1}: '{artifact_name}'")
                    
                    # –ò—â–µ–º —Å—Ç–∞—Ç—É—Å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–µ
                    status = '–ù–ï –ù–ê–ô–î–ï–ù'
                    source = '–ù–µ —É–∫–∞–∑–∞–Ω'
                    description = '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'
                    
                    # –°–ø–æ—Å–æ–± 1: –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –±–ª–æ–∫ –ø–æ –ø–æ—Ä—è–¥–∫—É
                    if i < len(blocks):
                        block = blocks[i]
                        artifact_info = self._parse_artifact_block(block)
                        if artifact_info and artifact_info.get('status'):
                            status = artifact_info['status']
                            source = artifact_info.get('source', '–ò–∑ –æ—Ç–≤–µ—Ç–∞ LLM')
                            description = artifact_info.get('description', '–ù–∞–π–¥–µ–Ω–æ –≤ –∞–Ω–∞–ª–∏–∑–µ')
                            print(f"      ‚úÖ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞–π–¥–µ–Ω–∞ –≤ –±–ª–æ–∫–µ {i+1}")
                    
                    # –°–ø–æ—Å–æ–± 2: –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–µ –æ—Ç–≤–µ—Ç–∞
                    if status == '–ù–ï –ù–ê–ô–î–ï–ù':
                        # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –≤ –æ—Ç–≤–µ—Ç–µ
                        artifact_words = artifact_name.lower().split()
                        response_lower = response_text.lower()
                        
                        # –ï—Å–ª–∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —Å–ª–æ–≤ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤ –æ—Ç–≤–µ—Ç–µ
                        mentioned_words = sum(1 for word in artifact_words if word in response_lower)
                        if mentioned_words >= len(artifact_words) * 0.6:  # 60% —Å–ª–æ–≤ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è
                            # –ò—â–µ–º —Å—Ç–∞—Ç—É—Å –≤ —Ç–µ–∫—Å—Ç–µ
                            if any(word in response_lower for word in ['–Ω–∞–π–¥–µ–Ω', '–µ—Å—Ç—å', '—Å–æ–¥–µ—Ä–∂–∏—Ç', '–ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç']):
                                status = '–ù–ê–ô–î–ï–ù'
                                description = f'–£–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤ –æ—Ç–≤–µ—Ç–µ (—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤: {mentioned_words}/{len(artifact_words)})'
                                source = '–û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º'
                                print(f"      üîç –ù–∞–π–¥–µ–Ω–æ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º")
                    
                    # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–µ —Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º
                    final_artifact_info = {
                        'name': artifact_name,  # –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–∂–∏–¥–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                        'status': status,
                        'source': source,
                        'description': description,
                        'unique_key': artifact_name
                    }
                    
                    print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω –∞—Ä—Ç–µ—Ñ–∞–∫—Ç: {final_artifact_info['name']} - {final_artifact_info['status']}")
                    print(f"      üìÇ –ò—Å—Ç–æ—á–Ω–∏–∫: {final_artifact_info.get('source', '–Ω–µ —É–∫–∞–∑–∞–Ω')}")
                    
                    status_upper = final_artifact_info['status'].upper()
                    
                    # –£–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞
                    if '–ù–ê–ô–î–ï–ù' in status_upper:
                        if '–ù–ï –ù–ê–ô–î–ï–ù' in status_upper:
                            result['not_found_artifacts'].append(final_artifact_info)
                            result['summary']['not_found_count'] += 1
                        elif '–ß–ê–°–¢–ò–ß–ù–û' in status_upper or 'PARTIAL' in status_upper:
                            result['partially_found_artifacts'].append(final_artifact_info)
                            result['summary']['partially_found_count'] += 1
                        else:
                            result['found_artifacts'].append(final_artifact_info)
                            result['summary']['found_count'] += 1
                    elif any(keyword in status_upper for keyword in ['FOUND', '–ï–°–¢–¨', '–ü–†–ò–°–£–¢–°–¢–í–£–ï–¢']):
                        result['found_artifacts'].append(final_artifact_info)
                        result['summary']['found_count'] += 1
                    elif any(keyword in status_upper for keyword in ['PARTIAL', '–ß–ê–°–¢–ò–ß–ù']):
                        result['partially_found_artifacts'].append(final_artifact_info)
                        result['summary']['partially_found_count'] += 1
                    else:
                        result['not_found_artifacts'].append(final_artifact_info)
                        result['summary']['not_found_count'] += 1
                    
                    result['summary']['total_artifacts'] += 1
            else:
                print(f"‚ö†Ô∏è expected_artifacts –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω - –Ω–µ–ª—å–∑—è –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑")
                # –ë–µ–∑ –æ–∂–∏–¥–∞–µ–º—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –Ω–µ –º–æ–∂–µ–º –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                return result
            
            print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞: {result['summary']['total_artifacts']} –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
            
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã, —Å–æ–∑–¥–∞–µ–º –∏—Ö –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ
            if expected_artifacts and result['summary']['total_artifacts'] == 0:
                print(f"‚ö†Ô∏è –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –¥–ª—è {len(expected_artifacts)} –æ–∂–∏–¥–∞–µ–º—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                for artifact in expected_artifacts:
                    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–µ –æ—Ç–≤–µ—Ç–∞
                    if artifact.lower() in response_text.lower():
                        status = '–ù–ê–ô–î–ï–ù' if any(word in response_text.lower() for word in ['–Ω–∞–π–¥–µ–Ω', '–µ—Å—Ç—å', '—Å–æ–¥–µ—Ä–∂–∏—Ç', '–ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç']) else '–ù–ï –ù–ê–ô–î–ï–ù'
                    else:
                        status = '–ù–ï –ù–ê–ô–î–ï–ù'
                    
                    artifact_info = {
                        'name': artifact,
                        'status': status,
                        'source': '–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ',
                        'description': f'–°—Ç–∞—Ç—É—Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–≤–µ—Ç–∞ LLM',
                        'unique_key': artifact
                    }
                    
                    if status == '–ù–ê–ô–î–ï–ù':
                        result['found_artifacts'].append(artifact_info)
                        result['summary']['found_count'] += 1
                    else:
                        result['not_found_artifacts'].append(artifact_info)
                        result['summary']['not_found_count'] += 1
                    
                    result['summary']['total_artifacts'] += 1
                
                print(f"‚úÖ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞–Ω–æ {result['summary']['total_artifacts']} –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –æ—Ç–≤–µ—Ç–∞ LLM: {str(e)}")
            print(f"üìã –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç LLM –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏:")
            print(f"‚îÄ" * 80)
            print(response_text[:2000] + ("..." if len(response_text) > 2000 else ""))
            print(f"‚îÄ" * 80)
            
        return result
    
    def _parse_artifact_block(self, block: str) -> Dict[str, str]:
        """–ü–∞—Ä—Å–∏—Ç –±–ª–æ–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–µ"""
        try:
            lines = [line.strip() for line in block.split('\n') if line.strip()]
            
            artifact_info = {
                'name': '',
                'status': '',
                'source': '',
                'description': '',
                'instance_id': ''  # –î–ª—è —Ä–∞–∑–ª–∏—á–µ–Ω–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ –æ–¥–Ω–æ–≥–æ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞
            }
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ –∏–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ
            first_line = lines[0] if lines else ""
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –∏–∑ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –±–ª–æ–∫–∞
            if first_line:
                # –£–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∏—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                clean_line = first_line.replace('**', '').replace('*', '').strip()
                
                # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å–ª—É–∂–µ–±–Ω–æ–µ –ø–æ–ª–µ, —Ç–æ —ç—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞
                if not any(keyword in clean_line.lower() for keyword in ['—Å—Ç–∞—Ç—É—Å:', '–∏—Å—Ç–æ—á–Ω–∏–∫:', '–æ–ø–∏—Å–∞–Ω–∏–µ:']):
                    # –ï—Å–ª–∏ –µ—Å—Ç—å "–ê–†–¢–ï–§–ê–ö–¢:" - –±–µ—Ä–µ–º —á–∞—Å—Ç—å –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è
                    if '–∞—Ä—Ç–µ—Ñ–∞–∫—Ç:' in clean_line.lower():
                        parts = clean_line.split(':', 1)
                        if len(parts) > 1:
                            artifact_info['name'] = parts[1].strip()
                        else:
                            artifact_info['name'] = clean_line
                    else:
                        artifact_info['name'] = clean_line
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ, –∏—â–µ–º –≤ –±–ª–æ–∫–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ "–ê–†–¢–ï–§–ê–ö–¢:"
            if not artifact_info['name']:
                for line in lines:
                    if '–∞—Ä—Ç–µ—Ñ–∞–∫—Ç' in line.lower() and ':' in line:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è
                        name_part = line.split(':', 1)[1].strip()
                        artifact_info['name'] = name_part.replace('**', '').replace('*', '').strip()
                        break
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
            for line in lines:
                line = line.strip()
                line_lower = line.lower()
                
                if '—Å—Ç–∞—Ç—É—Å:' in line_lower:
                    status_pos = line_lower.find('—Å—Ç–∞—Ç—É—Å:')
                    if status_pos != -1:
                        status_text = line[status_pos + 7:].strip()
                        artifact_info['status'] = status_text.replace('*', '').strip()
                        
                elif '–∏—Å—Ç–æ—á–Ω–∏–∫:' in line_lower:
                    source_pos = line_lower.find('–∏—Å—Ç–æ—á–Ω–∏–∫:')
                    if source_pos != -1:
                        source_text = line[source_pos + 9:].strip()
                        source_text = source_text.replace('*', '').replace('+', '').strip()
                        if source_text:
                            artifact_info['source'] = source_text
                        
                elif '–æ–ø–∏—Å–∞–Ω–∏–µ:' in line_lower:
                    desc_pos = line_lower.find('–æ–ø–∏—Å–∞–Ω–∏–µ:')
                    if desc_pos != -1:
                        desc_text = line[desc_pos + 9:].strip()
                        artifact_info['description'] = desc_text.replace('*', '').strip()
            
            # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É –∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            if not artifact_info['name'] and artifact_info['description']:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –∫–∞–∫ –Ω–∞–∑–≤–∞–Ω–∏–µ
                desc_words = artifact_info['description'].split()[:3]
                artifact_info['name'] = ' '.join(desc_words) + '...'
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ —Å—Ç–∞—Ç—É—Å –Ω–µ –Ω–∞–π–¥–µ–Ω —è–≤–Ω–æ
            if not artifact_info['status'] and artifact_info['name']:
                # –ü–æ–ø—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                block_lower = block.lower()
                if any(word in block_lower for word in ['–Ω–∞–π–¥–µ–Ω', '–µ—Å—Ç—å', '–ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç', '—Å–æ–¥–µ—Ä–∂–∏—Ç']):
                    artifact_info['status'] = '–ù–ê–ô–î–ï–ù'
                elif any(word in block_lower for word in ['–Ω–µ –Ω–∞–π–¥–µ–Ω', '–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç', '–Ω–µ—Ç']):
                    artifact_info['status'] = '–ù–ï –ù–ê–ô–î–ï–ù'
                elif any(word in block_lower for word in ['—á–∞—Å—Ç–∏—á–Ω–æ', '–Ω–µ–ø–æ–ª–Ω—ã–π', '—á–∞—Å—Ç–∏—á–Ω']):
                    artifact_info['status'] = '–ß–ê–°–¢–ò–ß–ù–û –ù–ê–ô–î–ï–ù'
                else:
                    # –ï—Å–ª–∏ –µ—Å—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤/–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –Ω–∞–π–¥–µ–Ω
                    if any(word in block_lower for word in ['—Ñ–∞–π–ª:', '–¥–æ–∫—É–º–µ–Ω—Ç', '—Å—Ç—Ä–∞–Ω–∏—Ü', 'confluence']):
                        artifact_info['status'] = '–ù–ê–ô–î–ï–ù'
                    else:
                        artifact_info['status'] = '–ù–ï –ù–ê–ô–î–ï–ù'
                
                print(f"   üîç –°—Ç–∞—Ç—É—Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: '{artifact_info['status']}'")
            
            # –ï—Å–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—É—Å—Ç–æ–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å –±–ª–æ–∫
            if not artifact_info['description'] and artifact_info['name']:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –≤—Å–µ–≥–æ –±–ª–æ–∫–∞, –∏—Å–∫–ª—é—á–∞—è —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                desc_lines = []
                for line in lines:
                    if not any(keyword in line.lower() for keyword in ['—Å—Ç–∞—Ç—É—Å:', '–∏—Å—Ç–æ—á–Ω–∏–∫:', '–æ–ø–∏—Å–∞–Ω–∏–µ:']):
                        clean_line = line.replace('**', '').replace('*', '').strip()
                        if clean_line and clean_line != artifact_info['name']:
                            desc_lines.append(clean_line)
                
                if desc_lines:
                    artifact_info['description'] = ' '.join(desc_lines[:3])  # –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ
            if artifact_info['name'] and artifact_info['status']:
                # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á
                artifact_info['unique_key'] = artifact_info['name']
                print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω: '{artifact_info['name']}' - {artifact_info['status']}")
                return artifact_info
            else:
                print(f"   ‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: name='{artifact_info['name']}', status='{artifact_info['status']}'")
                print(f"   üìÑ –ë–ª–æ–∫ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ: {block[:200]}...")
                return None
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –±–ª–æ–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞: {str(e)}")
            return None
    
    def _prepare_documents_info(self, documents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö"""
        documents_info = []
        
        for doc in documents:
            doc_info = {
                'name': doc.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç'),
                'type': doc.get('type', 'unknown'),
                'pages': doc.get('pages', 0),
                'text_length': len(doc.get('text', ''))
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–æ–ª—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            if doc['type'] == 'file':
                doc_info['format'] = doc.get('format', '')
                doc_info['size_bytes'] = doc.get('size', 0)
            elif doc['type'] == 'confluence':
                doc_info['url'] = doc.get('url', '')
                doc_info['last_modified'] = doc.get('last_modified', '')
            
            documents_info.append(doc_info)
        
        return documents_info
    
    def _create_empty_result(self, project_types: List[str], documents: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏"""
        result = {
            'found_artifacts': [],
            'not_found_artifacts': [],
            'partially_found_artifacts': [],
            'summary': {
                'total_artifacts': 0,
                'found_count': 0,
                'not_found_count': 0,
                'partially_found_count': 0
            },
            'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã'
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö, –¥–∞–∂–µ –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è
        if documents:
            result['analyzed_documents'] = self._prepare_documents_info(documents)
        else:
            result['analyzed_documents'] = []
        
        return result 